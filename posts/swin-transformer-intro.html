<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <script>if(localStorage.getItem('theme')==='light')document.documentElement.setAttribute('data-theme','light');</script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Swin Transformer 论文解读 - Pure Fruit</title>
    <link rel="icon" href="../Icon.png" type="image/png">
    <link rel="stylesheet" href="../style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
    <!-- 右侧功能按钮组 -->
    <div class="toggle-buttons">
        <a href="../index.html" class="home-toggle" title="返回主页">
            <i class="fas fa-home"></i>
        </a>
        <button class="theme-toggle" onclick="toggleTheme()" title="切换日间/夜间模式">
            <i class="fas fa-moon"></i>
        </button>
        <button class="lang-toggle" onclick="toggleLanguage()" title="切换中英文">
            <span id="langText">EN</span>
        </button>
    </div>

    <div class="article-container">
        <a href="../blog.html" class="back-link">← 返回博客</a>
        
        <article>
            <header class="article-header">
                <span class="post-tag tag-note">学习笔记</span>
                <h1 id="title-zh">Swin Transformer 论文解读</h1>
                <h1 id="title-en" style="display: none;">Swin Transformer Paper Review</h1>
                <div class="post-meta">2026-01-12 • Pure Tao</div>
            </header>
            
            <div class="article-content" id="content-zh">
                <h2>背景</h2>
                <p>Vision Transformer (ViT) 将 Transformer 架构引入计算机视觉领域，取得了很好的效果。但 ViT 存在一个问题：全局自注意力的计算复杂度是 O(n²)，当图像分辨率增大时，计算量会急剧增加。</p>
                
                <p>Swin Transformer 作为 <strong>ICCV 2021 Best Paper</strong>，提出了优雅的解决方案。</p>
                
                <h2>Swin Transformer 的核心思想</h2>
                <p>Swin Transformer 提出了两个关键创新：</p>
                
                <p><strong>1. 层次化结构（Hierarchical Structure）</strong></p>
                <p>类似于 CNN，Swin Transformer 采用层次化设计，随着网络加深，特征图的分辨率逐渐降低，通道数逐渐增加。这使得它可以方便地用于密集预测任务（如目标检测、语义分割）。</p>
                
                <p><strong>2. 移位窗口自注意力（Shifted Window Self-Attention）</strong></p>
                <p>不同于 ViT 的全局自注意力，Swin Transformer 在局部窗口内计算自注意力，将复杂度从 O(n²) 降低到 O(n)。通过在连续层之间移位窗口，实现了跨窗口的信息交互。</p>
                
                <h2>模型变体</h2>
                <ul>
                    <li><strong>Swin-Tiny</strong>: 28M 参数</li>
                    <li><strong>Swin-Small</strong>: 50M 参数</li>
                    <li><strong>Swin-Base</strong>: 88M 参数</li>
                    <li><strong>Swin-Large</strong>: 197M 参数</li>
                </ul>
                
                <h2>实验效果</h2>
                <p>Swin Transformer 在 ImageNet 图像分类、COCO 目标检测、ADE20K 语义分割等任务上都取得了 SOTA 效果，证明了其作为通用视觉骨干网络的潜力。</p>
                
                <h2>总结</h2>
                <p>Swin Transformer 通过层次化结构和移位窗口机制，成功地将 Transformer 应用于各种视觉任务，是 Vision Transformer 发展的重要里程碑。</p>
                
                <p>相关链接：<a href="https://arxiv.org/abs/2103.14030" target="_blank" style="color: var(--accent);">论文原文</a> | <a href="../projects/swin-transformer.html" style="color: var(--accent);">我们的实现</a></p>
            </div>
            
            <div class="article-content" id="content-en" style="display: none;">
                <h2>Background</h2>
                <p>Vision Transformer (ViT) introduced the Transformer architecture to computer vision and achieved excellent results. However, ViT has a problem: the computational complexity of global self-attention is O(n²), which increases dramatically as image resolution grows.</p>
                
                <p>Swin Transformer, as the <strong>ICCV 2021 Best Paper</strong>, proposed an elegant solution.</p>
                
                <h2>Core Ideas of Swin Transformer</h2>
                <p>Swin Transformer introduces two key innovations:</p>
                
                <p><strong>1. Hierarchical Structure</strong></p>
                <p>Similar to CNNs, Swin Transformer adopts a hierarchical design where feature map resolution gradually decreases and channel numbers gradually increase as the network deepens. This makes it convenient for dense prediction tasks (such as object detection and semantic segmentation).</p>
                
                <p><strong>2. Shifted Window Self-Attention</strong></p>
                <p>Unlike ViT's global self-attention, Swin Transformer computes self-attention within local windows, reducing complexity from O(n²) to O(n). By shifting windows between consecutive layers, it enables cross-window information interaction.</p>
                
                <h2>Model Variants</h2>
                <ul>
                    <li><strong>Swin-Tiny</strong>: 28M parameters</li>
                    <li><strong>Swin-Small</strong>: 50M parameters</li>
                    <li><strong>Swin-Base</strong>: 88M parameters</li>
                    <li><strong>Swin-Large</strong>: 197M parameters</li>
                </ul>
                
                <h2>Experimental Results</h2>
                <p>Swin Transformer achieved SOTA results on ImageNet image classification, COCO object detection, ADE20K semantic segmentation, and other tasks, demonstrating its potential as a general vision backbone.</p>
                
                <h2>Conclusion</h2>
                <p>Through hierarchical structure and shifted window mechanism, Swin Transformer successfully applied Transformer to various vision tasks, marking an important milestone in Vision Transformer development.</p>
                
                <p>Related Links: <a href="https://arxiv.org/abs/2103.14030" target="_blank" style="color: var(--accent);">Paper</a> | <a href="../projects/swin-transformer.html" style="color: var(--accent);">Our Implementation</a></p>
            </div>
        </article>
    </div>

    <footer>
        <p>
            <span class="text-zh">本文阅读量</span><span class="text-en" style="display: none;">Page Views</span> <span id="busuanzi_value_page_pv"></span> <span class="text-zh">次</span><span class="text-en" style="display: none;">times</span>
        </p>
        <p>&copy; 2026 Pure Fruit Team</p>
    </footer>

    <!-- 不蒜子统计 -->
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <script>
        function toggleTheme() {
            const html = document.documentElement;
            const btn = document.querySelector('.theme-toggle i');
            if (html.getAttribute('data-theme') === 'light') {
                html.removeAttribute('data-theme');
                btn.className = 'fas fa-moon';
                localStorage.setItem('theme', 'dark');
            } else {
                html.setAttribute('data-theme', 'light');
                btn.className = 'fas fa-sun';
                localStorage.setItem('theme', 'light');
            }
        }
        if (localStorage.getItem('theme') === 'light') {
            document.documentElement.setAttribute('data-theme', 'light');
            document.querySelector('.theme-toggle i').className = 'fas fa-sun';
        }
        
        // 语言切换功能
        let currentLang = 'zh';
        function toggleLanguage() {
            const titleZh = document.getElementById('title-zh');
            const titleEn = document.getElementById('title-en');
            const contentZh = document.getElementById('content-zh');
            const contentEn = document.getElementById('content-en');
            const langText = document.getElementById('langText');
            
            if (currentLang === 'zh') {
                titleZh.style.display = 'none';
                titleEn.style.display = 'block';
                contentZh.style.display = 'none';
                contentEn.style.display = 'block';
                langText.textContent = '中';
                currentLang = 'en';
            } else {
                titleZh.style.display = 'block';
                titleEn.style.display = 'none';
                contentZh.style.display = 'block';
                contentEn.style.display = 'none';
                langText.textContent = 'EN';
                currentLang = 'zh';
            }
        }
    </script>
</body>
</html>